Empecé con el prompt base: “Simula el diseño de una arquitectura cloud para una app de banca móvil usando nube híbrida y funciones serverless. Muestra el código del backend básico y el diagrama arquitectónico”. Con ese punto de partida, la IA me propuso una topología clara: app móvil → API Gateway → Lambdas por dominio (auth, account, transfers, notifications, payments, reports) → base de datos en la nube, más logs y trazas. Desde ahí fui afinando el prompt con detalles concretos de mi stack para que el resultado se pareciera a lo que necesito entregar y a lo que sé operar.

Un aprendizaje clave fue que mientras más específico soy, mejor sale: pedí Node.js 18, serverless.yml con stages (dev/prod), handler por carpeta, carga de variables con .env, y que me diera comandos de prueba. También pedí que la política IAM fuera de “mínimo privilegio” y que marcara comentarios en el código. La IA generó los handlers de ejemplo y la configuración para serverless-offline, lo que me permitió correr todo local en localhost y validar que los endpoints respondieran.

En la parte “híbrida” decidí mantener dos caminos: para desarrollo, MongoDB local (simple de levantar en mi PC o en Docker); para la nube, DynamoDB como opción serverless. La IA sugirió conectar el plano cloud con recursos en red privada (VPC + VPN/Direct Connect) para un core bancario on-prem, y eso me ayudó a explicar el concepto de “híbrido” de forma aterrizada. También propuso usar S3 para reportes y CloudWatch/X-Ray para observabilidad. Todo eso quedó reflejado en el diagrama.

Sobre seguridad, la IA inicialmente me dio algo “genérico”. Yo ajusté: JWT con una clave de desarrollo en .env, pero con la nota de que en producción se debe mover a Secrets Manager/KMS, activar TLS, validar inputs y aplicar rate limiting/WAF. Esta fue una parte donde no me confié ciegamente: revisé qué permisos daba la plantilla y recorté lo que no era necesario. También verifiqué que los endpoints sensibles fueran POST y que no expusieran datos.

Para probar, usé dos estrategias: abrir en navegador los GET públicos y llamar con curl/Postman los POST como /auth/login. Algo que me pasó fue confundir el puerto: en mi serverless.yml estaba configurado 3001 y yo entraba a 3000. Ajusté eso y listo. Este tipo de detalles me recordó que la IA acelera, pero yo debo leer la consola y los archivos.

En cuanto al código, la IA me dio un esqueleto que ahorra tiempo: rutas por dominio, respuestas JSON claras y un readme básico. A partir de ahí puedo crecer los casos reales (transferencias, notificaciones, reportes a S3, etc.). Para el diagrama, pedí una versión en Mermaid para pegarla en el repo y otra explicación “en español simple” por si el profesor lo pide en clase.

Mi conclusión es que al usar IA en Cursor me ayudó a arrancar rápido, documentar y evitar “pantalla en blanco”. Aun así, la responsabilidad es mía: definir el contexto, revisar seguridad, probar endpoints y adaptar a los requisitos reales. Como siguiente paso, quiero integrar pruebas automáticas, pipeline de despliegue y estimar costos. La combinación de prompt engineering + criterio técnico es lo que realmente hace que valga la pena.